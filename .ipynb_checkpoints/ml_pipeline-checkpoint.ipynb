{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path, pickle, math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from constants import PROCESSED_PATH, RAW_PATH\n",
    "from runTraditionalModels import runTraditionalModels\n",
    "from runAutoML import runAutoML, runTPot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle, resample\n",
    "from sklearn.preprocessing import normalize, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafn = 'HOUR_00003.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(PROCESSED_PATH, datafn), na_values=['?', '!'])\n",
    "df.replace('!.+', np.nan, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_for_nan_columns = set(df.columns) - {'SUBJECT_ID', 'HADM_ID', 'AGE', 'GENDER', 'ETHNICITY','P TSTAGE','P STAGE','TSTAGE','STAGE'}\n",
    "df = df.astype({k: np.float64 for k in check_for_nan_columns}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where all features=nan\n",
    "row_nan_bool = np.logical_not(np.all(np.isnan(df.iloc[:,5:-1]), axis=1))\n",
    "df = df[row_nan_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['SUBJECT_ID', 'HADM_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_fn = os.path.join(RAW_PATH, 'd_ids_split.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ids = pickle.load(open(ids_fn, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = {}\n",
    "for dataset in split_ids:\n",
    "    split_df[dataset] = df[(df['SUBJECT_ID'].isin(split_ids[dataset][:,0])) & (df['HADM_ID'].isin(split_ids[dataset][:,1]))]\n",
    "devel = split_df['devel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in split_df:\n",
    "    print(k, split_df[k].shape)\n",
    "print('total', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#drop columns where all rows=nan\n",
    "check_nan = devel.isna().sum()\n",
    "devel.drop(labels=check_nan[(check_nan == devel.shape[0])].keys(), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devel = devel[devel.columns[[0,1,4,2,3] + list(range(5,len(devel.columns)))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = devel.iloc[:,3:-2]\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate Kruskal-Wallis H-test for each feature\n",
    "dfs_by_class = [data3.loc[devel['STAGE'] == c] for c in [0,1,2,3]]\n",
    "kruskals = {}\n",
    "for col in data3.columns:\n",
    "    col_in_classes = [np.asarray(c[col].dropna()) for c in dfs_by_class]\n",
    "    try:\n",
    "        kruskals[col] = sp.stats.kruskal(*col_in_classes)[1]\n",
    "    except ValueError:\n",
    "        kruskals[col] = 0\n",
    "           \n",
    "devel_kruskal = devel[list(devel.columns[:3])+[k for k, v in kruskals.items() if v > 0.05]+list(devel.columns[-2:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devel_kruskal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = devel_kruskal.mean()\n",
    "devel_kruskal.fillna(means, inplace=True)\n",
    "print(devel_kruskal.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate VIFs\n",
    "features = devel_kruskal[devel_kruskal.columns[3:-2]]\n",
    "print(features.columns)\n",
    "done = False\n",
    "while not done:\n",
    "    vifs = {}\n",
    "    for i, n in enumerate(features):\n",
    "        if i in range(3,features.shape[1]):\n",
    "            vifs[n] = variance_inflation_factor(np.asarray(features), i)\n",
    "    \n",
    "    drop_items = sorted(vifs.items(), reverse=True, key=lambda kv: kv[1])\n",
    "    if len(drop_items) > 0 and drop_items[0][1] >= 5:\n",
    "        features.drop(labels=[drop_item[0][1]], axis=1, inplace=True)\n",
    "    else:\n",
    "        done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devel_vif = devel_kruskal[list(devel_kruskal.columns[:3]) + list(features.columns) + list(devel_kruskal.columns[-2:])]\n",
    "devel_vif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devel_dist = {}\n",
    "for s in [0,1,2,3]:\n",
    "    devel_dist[s] = devel_vif[(devel_vif['STAGE'] == s)].shape[0] / devel_vif.shape[0]\n",
    "devel_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {subset: dict() for subset in ['test', 'valid']}\n",
    "for subset in counts:\n",
    "    for s in [0,1,2,3]:\n",
    "        counts[subset][s] = split_df[subset][(split_df[subset]['STAGE'] == s)].shape[0]\n",
    "\n",
    "dists = {subset: dict() for subset in ['test', 'valid']}\n",
    "for subset in dists:\n",
    "    for s in [0,1,2,3]:\n",
    "        dists[subset][s] = counts[subset][s] / split_df[subset].shape[0]\n",
    "ratios = {}\n",
    "for subset in dists:\n",
    "    print(subset, dists[subset])\n",
    "    ratios[subset] = {c: dists[subset][c]/devel_dist[c] for c in devel_dist}\n",
    "    print('ratio', ratios[subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df['test'].fillna(means, inplace=True)\n",
    "split_df['valid'].fillna(means, inplace=True)\n",
    "\n",
    "split_df['test'] = split_df['test'][devel_vif.columns]\n",
    "split_df['valid'] = split_df['valid'][devel_vif.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize = {subset: dict() for subset in ['test', 'valid']}\n",
    "for subset in ratios:\n",
    "    for c in ratios[subset]:\n",
    "        if ratios[subset][c] < 1:\n",
    "            num_syn = math.ceil((1-ratios[subset][c])*counts[subset][c])\n",
    "            print(subset, c, counts[subset][c], num_syn)\n",
    "            synthesize[subset][c] = num_syn\n",
    "synthesize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df['test'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_or_mean(x):\n",
    "    if x.name in [\"SUBJECT_ID\", \"HADM_ID\"]:\n",
    "        return 99999\n",
    "    elif x.name in [\"ETHNICITY\", \"TSTAGE\", \"STAGE\"]:\n",
    "        return np.random.choice(x.mode().dropna())\n",
    "    else:\n",
    "        return x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "for subset in synthesize:\n",
    "    for c in synthesize[subset]:\n",
    "        for s in range(synthesize[subset][c]):\n",
    "            samples = resample(\n",
    "                    split_df[subset][(split_df[subset]['STAGE'] == c)],\n",
    "                    n_samples=n_samples,\n",
    "                )\n",
    "            synth = samples.apply(mode_or_mean)\n",
    "            split_df[subset] = split_df[subset].append(synth, ignore_index=True)\n",
    "        print(subset, split_df[subset].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in synthesize:\n",
    "    for c in synthesize[subset]:\n",
    "        print(subset, c, split_df[subset][(split_df[subset]['STAGE'] == c)].shape[0])\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = split_df['test']\n",
    "valid = split_df['valid']\n",
    "\n",
    "train = devel_vif.drop(['SUBJECT_ID','HADM_ID','ETHNICITY','TSTAGE'], axis=1)\n",
    "testv = test.drop(['SUBJECT_ID','HADM_ID','ETHNICITY','TSTAGE'], axis=1)\n",
    "\n",
    "x_train = train.values[:, :-2]\n",
    "y_train = train.values[:, -1]\n",
    "x_train = normalize(x_train, axis=0)\n",
    "ohe = LabelBinarizer()\n",
    "ohe.fit(y_train.reshape(-1, 1))\n",
    "\n",
    "x_test = testv.values[:, :-2]\n",
    "x_test = normalize(x_test, axis=0)\n",
    "y_test = testv.values[:, -1]\n",
    "\n",
    "ohe_y_train = ohe.transform(y_train.reshape(-1,1))\n",
    "ohe_y_test = ohe.transform(y_test.reshape(-1,1))\n",
    "print(ohe_y_train.shape)\n",
    "print(ohe_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runTraditionalModels(x_train, ohe_y_train, x_test, ohe_y_test, datafn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aMLScore = runAutoML(train, testv)\n",
    "print(aMLScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runTPot(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
