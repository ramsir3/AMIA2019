{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, datetime, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import PROCESSED_PATH, RAW_PATH, DATA_PATH\n",
    "from rnn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "max_train_steps = 3\n",
    "loss_thresh = 1e-4\n",
    "display_step = 100\n",
    "H, F, S = 200, 178, 4\n",
    "batchSize = 100\n",
    "seed = None\n",
    "labelCol = 'STAGE6'\n",
    "labelStart = -12\n",
    "idsPath = os.path.join(RAW_PATH, 'd_ids_split.pickle')\n",
    "datapath = os.path.join(DATA_PATH, 'bypt500')\n",
    "savepath = os.path.join(DATA_PATH, 'model')\n",
    "\n",
    "# if len(sys.argv) > 1:\n",
    "#     with open(sys.argv[1], 'r') as cfgf:\n",
    "#         cfg = json.loads(cfgf.read())\n",
    "#         learning_rate = cfg.get('learning_rate', learning_rate)\n",
    "#         max_train_steps = cfg.get('max_train_steps', max_train_steps)\n",
    "#         loss_thresh = cfg.get('loss_thresh', loss_thresh)\n",
    "#         display_step = cfg.get('display_step', display_step)\n",
    "#         H, F, S = cfg.get('H_F_S', [H, F, S])\n",
    "#         batchSize = cfg.get('batchSize', batchSize)\n",
    "#         seed = cfg.get('seed', seed)\n",
    "#         labelCol = cfg.get('labelCol', labelCol)\n",
    "#         labelStart = cfg.get('labelStart', labelStart)\n",
    "#         idsPath = cfg.get('idsPath', idsPath)\n",
    "#         datapath = cfg.get('datapath', datapath)\n",
    "#         savepath = cfg.get('savepath', savepath)\n",
    "#         print('loaded config %s' % sys.argv[1])\n",
    "#         # print(cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ids = getSplitIds(idsPath)\n",
    "db = DataBatch(datapath, split_ids, batchSize=batchSize)\n",
    "print([(k, len(v)) for k, v in db.files.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainBatches = db.getBatchIterator('devel')\n",
    "testBatches = db.getBatchIterator('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(xs, batch_size):\n",
    "    with tf.variable_scope(\"MyRNN\"):\n",
    "        LSTMcells = [tf.contrib.rnn.LSTMCell(s) for s in [F, S]]\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(LSTMcells)\n",
    "        \n",
    "#         LSTMcell = tf.contrib.rnn.LSTMCell(F)\n",
    "#         MRcell = tf.contrib.rnn.MultiRNNCell([LSTMcell])\n",
    "#         cell=tf.contrib.rnn.OutputProjectionWrapper(MRcell, output_size=S)\n",
    "        \n",
    "        \n",
    "        initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        output, state = tf.nn.dynamic_rnn(cell, xs, initial_state=initial_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "xs = tf.placeholder(shape=[None, H, F], dtype=tf.float32)\n",
    "yt = tf.placeholder(shape=[None, H, S], dtype=tf.float32)\n",
    "batch_size = tf.placeholder(tf.int32, shape=[], name='batch_size')\n",
    "output = RNN(xs, batch_size)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.l2_loss(yt-output))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train=optimizer.minimize(loss)\n",
    "\n",
    "prediction = tf.nn.softmax(output)\n",
    "precat = tf.argmax(prediction, 2)\n",
    "labels = tf.argmax(yt, 2)\n",
    "correct_pred = tf.equal(precat, labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "confmat = tf.confusion_matrix(\n",
    "    labels=tf.reshape(labels, [-1]),\n",
    "    predictions=tf.reshape(tf.argmax(prediction, 2), [-1])\n",
    ")\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%memit \n",
    "pro, pre, tru = None, None, None\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "#     print(sess.run())\n",
    "    row_nan_bool = None\n",
    "    headers = None\n",
    "\n",
    "    prev_lss = 1\n",
    "    lss_change = None\n",
    "    step = 1\n",
    "\n",
    "    while (lss_change is None) or (lss_change > loss_thresh and step < max_train_steps):\n",
    "        nb = 1\n",
    "\n",
    "        # training\n",
    "        for batch in trainBatches.setSeed(seed):\n",
    "            # print('bnumnan', np.sum(np.isnan(batch)))\n",
    "            trn_ids, trn_X, trn_Y = None, None, None\n",
    "            if headers is None:\n",
    "                headers = db.getHeaders()\n",
    "                # batch, headers, row_nan_bool = dropNanCols(batch, headers, row_nan_bool)\n",
    "                # print(headers)\n",
    "                trn_ids, trn_X, trn_Y, hdrscut = prepareData(batch, headers, nclasses=4, labelCol=labelCol, labelStart=labelStart, debug=True) # \n",
    "                print(hdrscut)\n",
    "            else:\n",
    "                # batch, _, row_nan_bool = dropNanCols(batch, None, row_nan_bool)\n",
    "                trn_ids, trn_X, trn_Y, hdrscut = prepareData(batch, headers, nclasses=4, labelCol=labelCol, labelStart=labelStart)\n",
    "\n",
    "            # print('Batch', nb)\n",
    "            nb += 1\n",
    "            # Run optimization op (backprop)\n",
    "            lss, _ = sess.run([loss, train], feed_dict={xs:trn_X,yt:trn_Y, batch_size:trn_X.shape[0]})\n",
    "            # lss_change = abs(prev_lss-lss)/prev_lss\n",
    "            lss_change = prev_lss-lss\n",
    "\n",
    "            prev_lss = lss\n",
    "\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            (otp, acc,) = sess.run([output, accuracy],\n",
    "                                   feed_dict={xs:trn_X, yt:trn_Y, batch_size:trn_X.shape[0]})\n",
    "\n",
    "            # print('numnan', np.sum(np.isnan(otp)))\n",
    "            print(\"Step %5d | L2 Loss = %.4f, Train Accuracy = %.3f\" % (step, lss, acc))\n",
    "\n",
    "        step += 1\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    trn_lss, trn_acc = sess.run([loss, accuracy], feed_dict={xs:trn_X, yt:trn_Y, batch_size:trn_X.shape[0]})\n",
    "    print(\"Step %5d | L2 Loss = %.4f, Train Accuracy = %.3f\" % (step, lss, acc))\n",
    "\n",
    "    # testing\n",
    "    for test in testBatches.setSeed(seed):  \n",
    "        # test, _, _ = dropNanCols(batch, None, row_nan_bool)\n",
    "        tst_ids, tst_X, tst_Y, _ = prepareData(test, headers, nclasses=4, labelCol=labelCol, labelStart=labelStart)\n",
    "        prob, preb, trub = sess.run([output, precat, labels],\n",
    "                                     feed_dict={xs:tst_X, yt:tst_Y, batch_size:tst_X.shape[0]})\n",
    "        # print('numnan', np.sum(np.isnan(prob)))\n",
    "        if pre is None:\n",
    "            pro, pre, tru = prob, preb, trub\n",
    "        else:\n",
    "            pro = np.concatenate([pro, prob], axis=0) \n",
    "            pre = np.concatenate([pre, preb], axis=0)\n",
    "            tru = np.concatenate([tru, trub], axis=0)\n",
    "\n",
    "        cor = (pre == tru).flatten()\n",
    "        print('Test accuracy:', np.sum(cor) / len(cor))\n",
    "\n",
    "    mdir = datetime.datetime.now().strftime('%m%d%y%H%M%S')\n",
    "    saver.save(sess, os.path.join(savepath, mdir, 'model_%s.ckpt' % mdir))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsfn = os.path.join(PROCESSED_PATH, 'rnn_metrics_%s.csv' % datetime.datetime.now().strftime('%m%d%y%H%M%S'))\n",
    "aucsfn = os.path.join(PROCESSED_PATH, 'rnn_aucs_%s.csv' % datetime.datetime.now().strftime('%m%d%y%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveMetrics(tru, pre, metricsfn)\n",
    "saveAUCs(tru, pro, aucsfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnn_pipeline import runTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded config -f\n",
      "[('devel', 297), ('test', 102), ('valid', 101)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ram/Projects/AMIA2019/rnn_utils.py:140: RuntimeWarning: Mean of empty slice\n",
      "  means = np.nanmean(X, axis=1)\n",
      "/home/ram/Projects/AMIA2019/rnn_utils.py:141: RuntimeWarning: Mean of empty slice\n",
      "  xmeans = np.nanmean(means, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      "100 x 200 x 178\n",
      "  v x   h x   f\n",
      "output:\n",
      "100 x 200 x   4\n",
      "  v x   h x   s\n",
      "\n",
      "['AGE' 'GENDER' 'P WEIGHT' 'P HEIGHT' 'P SYSTOLIC BP' 'P DIASTOLIC BP'\n",
      " 'P TEMPERATURE' 'P RESPIRATORY RATE' 'P HEART RATE' 'P SPO2'\n",
      " 'P CREATININE' 'P UREA NITROGEN' 'P HEMATOCRIT' 'P PLATELET COUNT'\n",
      " 'P WHITE BLOOD CELLS' 'P HEMOGLOBIN' 'P MCHC' 'P MCH' 'P MCV'\n",
      " 'P RED BLOOD CELLS' 'P RDW' 'P POTASSIUM' 'P SODIUM' 'P CHLORIDE'\n",
      " 'P BICARBONATE' 'P ANION GAP' 'P GLUCOSE' 'P MAGNESIUM' 'P PHOSPHATE'\n",
      " 'P CALCIUM' 'P INR(PT)' 'P PT' 'P PTT' 'P PH' 'P PH' 'P SPECIFIC GRAVITY'\n",
      " 'P LYMPHOCYTES' 'P MONOCYTES' 'P NEUTROPHILS' 'P BASOPHILS'\n",
      " 'P EOSINOPHILS' 'P BASE EXCESS' 'P CALCULATED TOTAL CO2' 'P PO2' 'P PCO2'\n",
      " 'P LACTATE' 'P ALANINE AMINOTRANSFERASE (ALT)'\n",
      " 'P ASPARATE AMINOTRANSFERASE (AST)' 'P PROTEIN' 'P BILIRUBIN'\n",
      " 'P ALKALINE PHOSPHATASE' 'P KETONE' 'P UROBILINOGEN' 'P GLUCOSE'\n",
      " 'P ALBUMIN' 'P URINE COLOR' 'P YEAST' 'P WBC' 'P RBC' 'P LEUKOCYTES'\n",
      " 'P EPITHELIAL CELLS' 'P POTASSIUM' 'P FREE CALCIUM'\n",
      " 'P CREATINE KINASE (CK)' 'P GLUCOSE' 'P CREATINE KINASE' 'P BACTERIA'\n",
      " 'P LACTATE DEHYDROGENASE (LD)' 'P HEMATOCRIT' 'P HEMOGLOBIN' 'P SODIUM'\n",
      " 'P OXYGEN SATURATION' 'P LIPASE' 'P TROPONIN T' 'P CHLORIDE'\n",
      " 'P TEMPERATURE' 'P OXYGEN' 'P AMYLASE' 'P BANDS' 'P FIBRINOGEN'\n",
      " 'P TIDAL VOLUME' 'P LENGTH OF URINE COLLECTION' 'P HYPOCHROMIA'\n",
      " 'P CREATININE' 'P PEEP' 'P ATYPICAL LYMPHOCYTES' 'P METAMYELOCYTES'\n",
      " 'P MYELOCYTES' 'P ANISOCYTOSIS' 'P SODIUM' 'WEIGHT' 'HEIGHT'\n",
      " 'SYSTOLIC BP' 'DIASTOLIC BP' 'TEMPERATURE' 'RESPIRATORY RATE'\n",
      " 'HEART RATE' 'SPO2' 'CREATININE' 'UREA NITROGEN' 'HEMATOCRIT'\n",
      " 'PLATELET COUNT' 'WHITE BLOOD CELLS' 'HEMOGLOBIN' 'MCHC' 'MCH' 'MCV'\n",
      " 'RED BLOOD CELLS' 'RDW' 'POTASSIUM' 'SODIUM' 'CHLORIDE' 'BICARBONATE'\n",
      " 'ANION GAP' 'GLUCOSE' 'MAGNESIUM' 'PHOSPHATE' 'CALCIUM' 'INR(PT)' 'PT'\n",
      " 'PTT' 'PH' 'PH' 'SPECIFIC GRAVITY' 'LYMPHOCYTES' 'MONOCYTES'\n",
      " 'NEUTROPHILS' 'BASOPHILS' 'EOSINOPHILS' 'BASE EXCESS'\n",
      " 'CALCULATED TOTAL CO2' 'PO2' 'PCO2' 'LACTATE'\n",
      " 'ALANINE AMINOTRANSFERASE (ALT)' 'ASPARATE AMINOTRANSFERASE (AST)'\n",
      " 'PROTEIN' 'BILIRUBIN' 'ALKALINE PHOSPHATASE' 'KETONE' 'UROBILINOGEN'\n",
      " 'GLUCOSE' 'ALBUMIN' 'URINE COLOR' 'YEAST' 'WBC' 'RBC' 'LEUKOCYTES'\n",
      " 'EPITHELIAL CELLS' 'POTASSIUM' 'FREE CALCIUM' 'CREATINE KINASE (CK)'\n",
      " 'GLUCOSE' 'CREATINE KINASE' 'BACTERIA' 'LACTATE DEHYDROGENASE (LD)'\n",
      " 'HEMATOCRIT' 'HEMOGLOBIN' 'SODIUM' 'OXYGEN SATURATION' 'LIPASE'\n",
      " 'TROPONIN T' 'CHLORIDE' 'TEMPERATURE' 'OXYGEN' 'AMYLASE' 'BANDS'\n",
      " 'FIBRINOGEN' 'TIDAL VOLUME' 'LENGTH OF URINE COLLECTION' 'HYPOCHROMIA'\n",
      " 'CREATININE' 'PEEP' 'ATYPICAL LYMPHOCYTES' 'METAMYELOCYTES' 'MYELOCYTES'\n",
      " 'ANISOCYTOSIS' 'SODIUM']\n",
      "Step     1 | L2 Loss = 10128.6113, Train Accuracy = 0.453\n",
      "Optimization Finished!\n",
      "Step     3 | L2 Loss = 6513.6313, Train Accuracy = 0.453\n",
      "Test accuracy: 0.24375\n",
      "Test accuracy: 0.2578921568627451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ram/Projects/AMIA2019/rnn_utils.py:196: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  ppv = rs[0]/(rs[0]+rs[1])\n",
      "/home/ram/Projects/AMIA2019/rnn_utils.py:199: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  spe = rs[2]/(rs[0]+rs[1])\n",
      "/home/ram/Projects/AMIA2019/rnn_utils.py:198: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  sen = rs[0]/(rs[0]+rs[3])\n",
      "/home/ram/Projects/AMIA2019/rnn_utils.py:200: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  f1  = (2*rs[0])/((2*rs[0])+rs[1]+rs[3])\n",
      "/home/ram/anaconda3/envs/tfenv/lib/python3.6/site-packages/sklearn/metrics/ranking.py:656: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  UndefinedMetricWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%mprun -f runTraining(\"/home/ram/Projects/AMIA2019/rnn2.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
