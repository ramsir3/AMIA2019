{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, datetime, sys\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from massageData import runPipeline, readData\n",
    "from constants import PROCESSED_PATH, RAW_PATH, DATA_PATH\n",
    "from rnn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idsPath = os.path.join(RAW_PATH, 'd_ids_split.pickle')\n",
    "split_ids = getSplitIds(idsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('devel', 318), ('test', 97), ('valid', 88)]\n"
     ]
    }
   ],
   "source": [
    "datapath = os.path.join(DATA_PATH, 'bypt_old')\n",
    "db = DataBatch(datapath, split_ids, batchSize=75)\n",
    "\n",
    "print([(k, len(v)) for k, v in db.files.items()])\n",
    "\n",
    "trainBatches = db.getBatchIterator('devel')\n",
    "testBatches = db.getBatchIterator('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "max_train_steps = 10000\n",
    "loss_thresh = 10\n",
    "display_step = 100\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, F, S = 24, 200, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(xs, batch_size):\n",
    "    with tf.variable_scope(\"MyRNN\"):\n",
    "        LSTMcells = [tf.contrib.rnn.LSTMCell(s) for s in [F, S]]\n",
    "        cell = tf.contrib.rnn.MultiRNNCell(LSTMcells)\n",
    "        \n",
    "#         LSTMcell = tf.contrib.rnn.LSTMCell(F)\n",
    "#         MRcell = tf.contrib.rnn.MultiRNNCell([LSTMcell])\n",
    "#         cell=tf.contrib.rnn.OutputProjectionWrapper(MRcell, output_size=S)\n",
    "        \n",
    "        \n",
    "        initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "        output, state = tf.nn.dynamic_rnn(cell, xs, initial_state=initial_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "xs = tf.placeholder(shape=[None, H, F], dtype=tf.float32)\n",
    "yt = tf.placeholder(shape=[None, H, S], dtype=tf.float32)\n",
    "batch_size = tf.placeholder(tf.int32, shape=[], name='batch_size')\n",
    "output = RNN(xs, batch_size)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.l2_loss(yt-output))\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train=optimizer.minimize(loss)\n",
    "\n",
    "prediction = tf.nn.softmax(output)\n",
    "precat = tf.argmax(prediction, 2)\n",
    "labels = tf.argmax(yt, 2)\n",
    "correct_pred = tf.equal(precat, labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "confmat = tf.confusion_matrix(\n",
    "    labels=tf.reshape(labels, [-1]),\n",
    "    predictions=tf.reshape(tf.argmax(prediction, 2), [-1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ram/Projects/AMIA2019/rnn_utils.py:124: RuntimeWarning: Mean of empty slice\n",
      "  means = np.nanmean(X, axis=1)\n",
      "/home/ram/Projects/AMIA2019/rnn_utils.py:125: RuntimeWarning: Mean of empty slice\n",
      "  xmeans = np.nanmean(means, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " 75 x  24 x 200\n",
      "  v x   h x   f\n",
      "output:\n",
      " 75 x  24 x   4\n",
      "  v x   h x   s\n",
      "\n",
      "['AGE' 'GENDER' 'ETHNICITY' 'P WEIGHT' 'P HEIGHT' 'P SYSTOLIC BP'\n",
      " 'P DIASTOLIC BP' 'P TEMPERATURE' 'P RESPIRATORY RATE' 'P HEART RATE'\n",
      " 'P SPO2' 'P CREATININE' 'P UREA NITROGEN' 'P HEMATOCRIT'\n",
      " 'P PLATELET COUNT' 'P WHITE BLOOD CELLS' 'P HEMOGLOBIN' 'P MCHC' 'P MCH'\n",
      " 'P MCV' 'P RED BLOOD CELLS' 'P RDW' 'P POTASSIUM' 'P SODIUM' 'P CHLORIDE'\n",
      " 'P BICARBONATE' 'P ANION GAP' 'P GLUCOSE' 'P MAGNESIUM' 'P PHOSPHATE'\n",
      " 'P CALCIUM' 'P INR(PT)' 'P PT' 'P PTT' 'P PH' 'P PH' 'P SPECIFIC GRAVITY'\n",
      " 'P LYMPHOCYTES' 'P MONOCYTES' 'P NEUTROPHILS' 'P BASOPHILS'\n",
      " 'P EOSINOPHILS' 'P BASE EXCESS' 'P CALCULATED TOTAL CO2' 'P PO2' 'P PCO2'\n",
      " 'P LACTATE' 'P ALANINE AMINOTRANSFERASE (ALT)'\n",
      " 'P ASPARATE AMINOTRANSFERASE (AST)' 'P PROTEIN' 'P BILIRUBIN'\n",
      " 'P ALKALINE PHOSPHATASE' 'P KETONE' 'P UROBILINOGEN' 'P GLUCOSE'\n",
      " 'P ALBUMIN' 'P URINE COLOR' 'P URINE APPEARANCE' 'P BLOOD' 'P BILIRUBIN'\n",
      " 'P NITRITE' 'P YEAST' 'P WBC' 'P RBC' 'P LEUKOCYTES' 'P EPITHELIAL CELLS'\n",
      " 'P POTASSIUM' 'P FREE CALCIUM' 'P CREATINE KINASE (CK)' 'P GLUCOSE'\n",
      " 'P CREATINE KINASE' 'P SPECIMEN TYPE' 'P BACTERIA'\n",
      " 'P LACTATE DEHYDROGENASE (LD)' 'P HEMATOCRIT' 'P HEMOGLOBIN' 'P SODIUM'\n",
      " 'P OXYGEN SATURATION' 'P INTUBATED' 'P LIPASE' 'P TROPONIN T'\n",
      " 'P CHLORIDE' 'P TEMPERATURE' 'P OXYGEN' 'P AMYLASE' 'P BANDS'\n",
      " 'P FIBRINOGEN' 'P TIDAL VOLUME' 'P LENGTH OF URINE COLLECTION'\n",
      " 'P VENTILATOR' 'P ESTIMATED GFR (MDRD EQUATION)' 'P HYPOCHROMIA'\n",
      " 'P CREATININE' 'P MACROCYTES' 'P PEEP' 'P ATYPICAL LYMPHOCYTES'\n",
      " 'P METAMYELOCYTES' 'P MYELOCYTES' 'P ANISOCYTOSIS' 'P MICROCYTES'\n",
      " 'P SODIUM' 'WEIGHT' 'HEIGHT' 'SYSTOLIC BP' 'DIASTOLIC BP' 'TEMPERATURE'\n",
      " 'RESPIRATORY RATE' 'HEART RATE' 'SPO2' 'CREATININE' 'UREA NITROGEN'\n",
      " 'HEMATOCRIT' 'PLATELET COUNT' 'WHITE BLOOD CELLS' 'HEMOGLOBIN' 'MCHC'\n",
      " 'MCH' 'MCV' 'RED BLOOD CELLS' 'RDW' 'POTASSIUM' 'SODIUM' 'CHLORIDE'\n",
      " 'BICARBONATE' 'ANION GAP' 'GLUCOSE' 'MAGNESIUM' 'PHOSPHATE' 'CALCIUM'\n",
      " 'INR(PT)' 'PT' 'PTT' 'PH' 'PH' 'SPECIFIC GRAVITY' 'LYMPHOCYTES'\n",
      " 'MONOCYTES' 'NEUTROPHILS' 'BASOPHILS' 'EOSINOPHILS' 'BASE EXCESS'\n",
      " 'CALCULATED TOTAL CO2' 'PO2' 'PCO2' 'LACTATE'\n",
      " 'ALANINE AMINOTRANSFERASE (ALT)' 'ASPARATE AMINOTRANSFERASE (AST)'\n",
      " 'PROTEIN' 'BILIRUBIN' 'ALKALINE PHOSPHATASE' 'KETONE' 'UROBILINOGEN'\n",
      " 'GLUCOSE' 'ALBUMIN' 'URINE COLOR' 'URINE APPEARANCE' 'BLOOD' 'BILIRUBIN'\n",
      " 'NITRITE' 'YEAST' 'WBC' 'RBC' 'LEUKOCYTES' 'EPITHELIAL CELLS' 'POTASSIUM'\n",
      " 'FREE CALCIUM' 'CREATINE KINASE (CK)' 'GLUCOSE' 'CREATINE KINASE'\n",
      " 'SPECIMEN TYPE' 'BACTERIA' 'LACTATE DEHYDROGENASE (LD)' 'HEMATOCRIT'\n",
      " 'HEMOGLOBIN' 'SODIUM' 'OXYGEN SATURATION' 'INTUBATED' 'LIPASE'\n",
      " 'TROPONIN T' 'CHLORIDE' 'TEMPERATURE' 'OXYGEN' 'AMYLASE' 'BANDS'\n",
      " 'FIBRINOGEN' 'TIDAL VOLUME' 'LENGTH OF URINE COLLECTION' 'VENTILATOR'\n",
      " 'ESTIMATED GFR (MDRD EQUATION)' 'HYPOCHROMIA' 'CREATININE' 'MACROCYTES'\n",
      " 'PEEP' 'ATYPICAL LYMPHOCYTES' 'METAMYELOCYTES' 'MYELOCYTES'\n",
      " 'ANISOCYTOSIS' 'MICROCYTES' 'SODIUM' 'TSTAGE']\n",
      "Step     0 | L2 Loss = 471.1126, Train Accuracy = 0.056\n",
      "Optimization Finished!\n",
      "Step     1 | L2 Loss = 471.1126, Train Accuracy = 0.056\n",
      "Test accuracy: 0.09222222222222222\n",
      "Test accuracy: 0.09664948453608248\n"
     ]
    }
   ],
   "source": [
    "pro, pre, tru = None, None, None\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(\"output\", sess.graph)\n",
    "#     print(sess.run())\n",
    "    row_nan_bool = None\n",
    "    headers = None\n",
    "    \n",
    "    prev_lss = 1\n",
    "    lss_ratio = 1\n",
    "    step = 0\n",
    "    first = True\n",
    "    while first or (lss_ratio > loss_thresh and step < max_train_steps):\n",
    "        nb = 1\n",
    "        for batch in trainBatches.setSeed(seed):\n",
    "            # print('bnumnan', np.sum(np.isnan(batch)))\n",
    "            trn_ids, trn_X, trn_Y = None, None, None\n",
    "            if headers is None:\n",
    "                headers = db.getHeaders()\n",
    "                # batch, headers, row_nan_bool = dropNanCols(batch, headers, row_nan_bool)\n",
    "                # print(headers)\n",
    "                trn_ids, trn_X, trn_Y, hdrscut = prepareData(batch, headers, nclasses=4, debug=True)\n",
    "                print(hdrscut)\n",
    "            else:\n",
    "                # batch, _, row_nan_bool = dropNanCols(batch, None, row_nan_bool)\n",
    "                trn_ids, trn_X, trn_Y, hdrscut = prepareData(batch, headers, nclasses=4)\n",
    "\n",
    "#             print('Batch', nb)\n",
    "            nb += 1\n",
    "            # Run optimization op (backprop)\n",
    "            lss, _ = sess.run([loss, train], feed_dict={xs:trn_X,yt:trn_Y, batch_size:trn_X.shape[0]})\n",
    "            lss_ratio = abs(prev_lss-lss)/prev_lss\n",
    "            prev_lss = lss\n",
    "            \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            (otp, acc,) = sess.run([output, accuracy],\n",
    "                                   feed_dict={xs:trn_X, yt:trn_Y, batch_size:trn_X.shape[0]})\n",
    "\n",
    "            # print('numnan', np.sum(np.isnan(otp)))\n",
    "            print(\"Step %5d | L2 Loss = %.4f, Train Accuracy = %.3f\" % (step, lss, acc))\n",
    "        \n",
    "        first = False\n",
    "        step += 1\n",
    "        \n",
    "    print(\"Optimization Finished!\")\n",
    "    trn_lss, trn_acc = sess.run([loss, accuracy], feed_dict={xs:trn_X, yt:trn_Y, batch_size:trn_X.shape[0]})\n",
    "    print(\"Step %5d | L2 Loss = %.4f, Train Accuracy = %.3f\" % (step, lss, acc))\n",
    "    \n",
    "    for test in testBatches.setSeed(seed):  \n",
    "#         test, _, _ = dropNanCols(batch, None, row_nan_bool)\n",
    "        tst_ids, tst_X, tst_Y, _ = prepareData(test, headers, nclasses=4)\n",
    "        prob, preb, trub = sess.run([output, precat, labels],\n",
    "                                     feed_dict={xs:tst_X, yt:tst_Y, batch_size:tst_X.shape[0]})\n",
    "#         print('numnan', np.sum(np.isnan(prob)))\n",
    "        if pre is None:\n",
    "            pro, pre, tru = prob, preb, trub\n",
    "        else:\n",
    "            pro = np.concatenate([pro, prob], axis=0) \n",
    "            pre = np.concatenate([pre, preb], axis=0)\n",
    "            tru = np.concatenate([tru, trub], axis=0)\n",
    "        \n",
    "        cor = (pre == tru).flatten()\n",
    "        print('Test accuracy:', np.sum(cor) / len(cor))\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricsfn = os.path.join(PROCESSED_PATH, 'rnn_metrics_%s.csv' % datetime.datetime.now().strftime('%m%d%y%H%M%S'))\n",
    "aucsfn = os.path.join(PROCESSED_PATH, 'rnn_aucs_%s.csv' % datetime.datetime.now().strftime('%m%d%y%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ram/Projects/AMIA2019/rnn_utils.py:180: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  ppv = rs[0]/(rs[0]+rs[1])\n",
      "/home/ram/Projects/AMIA2019/rnn_utils.py:183: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  spe = rs[2]/(rs[0]+rs[1])\n"
     ]
    }
   ],
   "source": [
    "saveMetrics(tru, pre, metricsfn)\n",
    "saveAUCs(tru, pro, aucsfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
